def constructEmissions(pr_correct,adj):
    ## This function takes in a matrix detailing the adjacent letters on a keyboard, and the
    #  probability of hitting the correct key and outputs a matrix of emission probabilities
    #
    ## INPUT
    # pr_correct - the probability of correctly hitting the intended key;
    # adj - a 26 x 26 matrix with adj[i][j] = 1 if the i'th letter in the alphabet is adjacent
    # to the j'th letter.
    #
    # OUTPUT
    # b - a 26 x 26 matrix with b[i][j] being the probability of hitting key j if you intended
    # to hit key i (the probabilities of hitting all adjacent keys are identical).

	## Your code goes here.

    # for row in adj:
    #     print(row)    

    # Pre-define the emission probability matrix
    b = adj
    
    # Create loop for each row (loop through intended keystroke)
    for i in range(26):
        
        # Determine how many keys are adjacent to the i'th intended key
        rowSum = sum(b[i])

        # Assign probabilities of hitting adjacent keys without intending to
        for j in range(26):
            if (adj[i][j] == 1):
                b[i][j] = (1-pr_correct)/rowSum
        
        # Assign probability of 0.5 (pr_correct) that the intended key is hit
        b[i][i] = pr_correct

    # for row in b:
    #     print(row)
        # print( 'rowSum: ' + str(sum(row)))
    return b

def constructTransitions(filename):
    # This function constructs tranisition matricies for lowercase characters.
    # It is assumed that the file 'filename' only contains lowercase characters
    # and whitespace.
    ## INPUT
    #  filename is the file containing the text from which we wish to develop a
    #  Markov process.
    #
    ## OUTPUT
    #  p is a 26 x 26 matrix containing the probabilities of transition from a
    #  state to another state, based on the frequencies observed in the text.
    #  prior is a vector of prior probabilities based on how often each character
    #  appears in the text

    ## Read the file into a sting called text
    with open(filename, 'r') as myfile:
    # with open('test.txt', 'r') as myfile:
        text = myfile.read()
        
	## Your code goes here.
    
    # Remove all whitespaces and other unwanted characters
    # text = text.replace(' ','')
    text = text.replace('  ','')
    text = text.replace('   ','')
    text = text.replace('\n','')
    text = text.replace('\r','')
    text = text.replace('(','')
    text = text.replace(')','')
    text = text.replace('!','')

    from collections import Counter
    
    # Initialise variable for frequency of each letter's appearance in corpus.
    res = Counter(text)

    # numLetters = sum(res.values())-res[" "] # not counting "space" characters
       
    # Initialise vector for priors
    priorf = [] # SURELY THERE'S A BETTER WAY TO DO THIS ask liam lol...
    # Fill vector of priors: proportion of each letter in corpus
    priorf.append(res["a"])
    priorf.append(res["b"])
    priorf.append(res["c"])
    priorf.append(res["d"])
    priorf.append(res["e"])
    priorf.append(res["f"])
    priorf.append(res["g"])
    priorf.append(res["h"])
    priorf.append(res["i"])
    priorf.append(res["j"])
    priorf.append(res["k"])
    priorf.append(res["l"])
    priorf.append(res["m"])
    priorf.append(res["n"])
    priorf.append(res["o"])
    priorf.append(res["p"])
    priorf.append(res["q"])
    priorf.append(res["r"])
    priorf.append(res["s"])
    priorf.append(res["t"])
    priorf.append(res["u"])
    priorf.append(res["v"])
    priorf.append(res["w"])
    priorf.append(res["x"])
    priorf.append(res["y"])
    priorf.append(res["z"])

    # Total number of letters in the entire corpus
    numLetters = sum(priorf)

    prior = []
    prior.append(res["a"]/numLetters)
    prior.append(res["b"]/numLetters)
    prior.append(res["c"]/numLetters)
    prior.append(res["d"]/numLetters)
    prior.append(res["e"]/numLetters)
    prior.append(res["f"]/numLetters)
    prior.append(res["g"]/numLetters)
    prior.append(res["h"]/numLetters)
    prior.append(res["i"]/numLetters)
    prior.append(res["j"]/numLetters)
    prior.append(res["k"]/numLetters)
    prior.append(res["l"]/numLetters)
    prior.append(res["m"]/numLetters)
    prior.append(res["n"]/numLetters)
    prior.append(res["o"]/numLetters)
    prior.append(res["p"]/numLetters)
    prior.append(res["q"]/numLetters)
    prior.append(res["r"]/numLetters)
    prior.append(res["s"]/numLetters)
    prior.append(res["t"]/numLetters)
    prior.append(res["u"]/numLetters)
    prior.append(res["v"]/numLetters)
    prior.append(res["w"]/numLetters)
    prior.append(res["x"]/numLetters)
    prior.append(res["y"]/numLetters)
    prior.append(res["z"]/numLetters)

    # print(text)
    # print(prior)
    numUniques = len(set(text))
    # print(numUniques)

    # Define ranking function to convert letters into numbers to compare them
    def rank(c):
        charRank = ord(c) - ord('a')
        if charRank < 0:
            charRank = numUniques - 1 
        # print(charRank)
        return charRank

    # Vectorise corpus into numbers (rank) with rank('a') = 0, rank('b') = 1 and so on.
    T = [rank(c) for c in text]
    # print(T)
    # print()
    # print(numUniques)
    # print()

    # Frequency table for occurrence of each letter AFTER a given letter 
    # (e.g. in the corpus, how many times a 'b' appears after an 'a' and so on.)
    p = [[0]*(numUniques - 1) for _ in range(numUniques - 1)]
    for (i,j) in zip(T,T[1:]):
        # print(i,j)
        if (i<numUniques-1) & (j<numUniques-1):
            p[i][j] += 1
    
    # print(prior)
    
    # for row in p:
    #     print(row)

    # print()
    # Convert frequencies to probabilities
    # (i.e. in the corpus, given we are on 'a', what is the probability of finding a 'b' next)
    for row in p:
        s = sum(row)
        # print(s)
        if s > 0:
            row[:] = [f/sum(row) for f in row]

    # for row in p:
    #     # print( 'rowSum: ' + str(sum(row)) + '   row: ' + str(row))
    #     print(row)

    return (p, prior)

def HMM(p,pi,b,y):
    ## This function implements the Viterbi algorithm, to find the most likely
    # sequence of states given some set of observations.
    #
    ## INPUT
    #  p is a matrix of transition probabilies for states x;
    #  pi is a vector of prior distributions for states x;
    #  b is a matrix of emission probabilities;
    #  y is a vector of observations.
    #
    ## OUTPUT
    # x is the most likely sequence of states, given the inputs.

    n=len(y) # length of word - i.e. number of letters in word (y = obsn)
    m=len(pi) # = 26 (number of letters!)
    # for row in b:
    #     print(row)
    # print(n,m)
    # print()

    gamma={} # define dictionaries for gamma and phi
    phi={}

    # print(type(gamma), type(phi))

    ## You must complete the code below
    for k in range(m): # IF ERROR, CHANGE 'm' to '26'
        # Your code goes here (initialisation)
        # print('i: ' + str(i) + '    y[i]:' + str(y[i]) + '    pi[i]' + str(pi[i]))
        
        # Here t = 0: Hence we're looking at 'gamma' at t = 0 and 'y' at t =0 (i.e. y_0, first character of given word)
        #             We do this for all k states (k = 0 to 26)
        # b[k]][y[0]] is the emission probability of seeing the first observation given we're in state 'k' of which there are 26!
        gamma[k,0] = b[k][y[0]] * pi[k]

    # print(gamma)
    # letter by letter, from 2nd letter to final letter of word
    for t in range(1,n):
        for k in range(m):
            array = []
            gamma[k,t]=0
            for j in range(m):
                # Your code goes here
                # print(p[j][k], gamma[j,(t-1)])
                array.append(p[j][k] * gamma[j,(t-1)])
            gamma[k,t] = b[k][y[t]] * max(array)
            phi[k,t] = array.index(max(array))
    
    print(phi)
    print()
    best=0
    x=[]
    
    for t in range(n):
        x.append(0)

    # Find the final state in the most likely sequence x(n).
    for k in range(m):
        if best<=gamma[k,n-1]:
            best=gamma[k,n-1]
            x[n-1]=k
    
    # Back track through states and find the remaining sequence from phi to find most likely state sequence
    for i in range(n-2,-1,-1):
        # Your code goes here
        best = 0
        for k in range(m):
            if best<=gamma[k,i]:
                best=gamma[k,i]
                x[i]=k
        # print(i)

    print(x)
    asdf
    
    # print()
    return x

def main():
    # The text messages you have received.
    msgs=[]
    # msgs.append('cljlx ypi ktxwf a pwfi psti vgicien aabdwucg vpd me and vtiex voe zoicw')
    msgs.append('ypi ktxwf a pwfi psti vgicien aabdwucg vpd me and vtiex voe zoicw')
    msgs.append('qe qzby yii tl gp tp yhr cpozwdt fwstqurzby')
    msgs.append('qee ypi xfjvkjv ygetw ib ulur vae')
    msgs.append('wgrrr zrw uiu')
    msgs.append('hpq fzr qee ypi vrpm grfw')
    msgs.append('qe zfr xtztvkmh')
    msgs.append('wgzf tjmr will uiu xjoq jp ywfw')

    #The probability of hitting the intended key.
    pr_correct= 0.5 # Complete this line

    # An adjacency matrix, adj(i,j) set to 1 if the i'th letter in the alphabet is next
    # to the j'th letter in the alphabet on the keclsyboard.
    adj=[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,1],[0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0],[0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0],[0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0],[0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0],[0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0],[0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0],[0,1,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,0],[0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,1,1,0,1,0,1,1,0,0,0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,0,1,1,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0],[0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],[1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1],[0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0],[0,1,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0],[0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1],[0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0]]

    # Call a function to construct the emission probabilities of hitting a key
    # given you tried to hit a (potentially) different key.
    b=constructEmissions(pr_correct,adj)
    # Call a function to construct transmission probabilities and a prior distribution
    # from the King James Bible.
    [p, prior]=constructTransitions('bible.txt')

    # p = [[0.004267948878586643, 0.021065655932840495, 0.023626425259992482, 0.028520862047362486, 0.010458432527252225, 0.007545263751409598, 0.01366526751033705, 0.01755340809422378, 0.05155995489287057, 0.00014879087833604812, 0.01973828467610575, 0.10322954516977823, 0.038955801278035336, 0.2895744580879589, 0.001284300213005889, 0.007870254354090967, 2.3493296579376018e-05, 0.08017479012655056, 0.066227603057261, 0.12087692645031951, 0.013340276907655681, 0.031156026813682496, 0.009087990226788623, 0.0005325147224658564, 0.037166395188572864, 0.002349329657937602], [0.06714435055318407, 0.00790574091819845, 0.0, 0.0012196184336614687, 0.4060022650056625, 0.0, 0.0, 0.0010671661294537852, 0.0371765833260737, 0.0007404826204373203, 0.0, 0.0660336266225281, 0.0005009147138252461, 0.0021996689607108634, 0.08813921073264222, 0.0, 0.0, 0.10719574875860266, 0.011869500827598222, 0.0024392368673229374, 0.13655370676888232, 0.00010889450300548829, 0.0, 0.0, 0.06350727415280076, 0.00019601010540987892], [0.16010682627471778, 0.0, 0.02094855670884158, 0.0, 0.1633835896658838, 0.0, 0.0, 0.2397340707629366, 0.046215622395636036, 0.0, 0.042238048336995224, 0.034358663535116296, 0.0, 1.8940828850670506e-05, 0.19520418213501023, 0.0, 0.0002841124327600576, 0.03515417834684446, 7.576331540268203e-05, 0.02363815440563679, 0.030968255170846275, 0.0, 0.0, 0.0, 0.0076710356845215545, 0.0], [0.1621985815602837, 0.00018912529550827424, 9.456264775413712e-05, 0.008794326241134751, 0.29557919621749407, 0.0016784869976359338, 0.027163120567375888, 0.00014184397163120567, 0.11773049645390071, 0.00016548463356973994, 4.728132387706856e-05, 0.012647754137115838, 0.012198581560283688, 0.012789598108747045, 0.1312293144208038, 0.0, 0.0, 0.09023640661938534, 0.07981087470449172, 0.0022931442080378252, 0.01442080378250591, 0.003144208037825059, 0.017375886524822696, 0.0, 0.010070921985815603, 0.0], [0.08390380605896901, 0.004971764765466072, 0.01803003317323519, 0.09315095088166525, 0.0460542420380015, 0.019376376942491284, 0.008525437034160836, 0.00976204745545248, 0.030864614371692172, 0.0013463437692560923, 0.003688728696958698, 0.05367648920814728, 0.04553933940524525, 0.12122158539364729, 0.01756155618769467, 0.01547662257637019, 0.000548666739822232, 0.1864622812718939, 0.10304383425199841, 0.0567068178173193, 0.0011859642606926706, 0.02791869603018511, 0.00933155509036119, 0.00315272349728621, 0.03649055871156168, 0.0020089643704260187], [0.10519048956285687, 2.3401666198633343e-05, 0.0, 7.020499859590003e-05, 0.1094261911448095, 0.06257605541514556, 0.0, 2.3401666198633343e-05, 0.10439483291210334, 0.0, 0.0, 0.03608536927829262, 0.0, 0.00021061499578770007, 0.38390433398858, 0.0, 0.0, 0.10453524290929514, 0.0012168866423289339, 0.05571936721894599, 0.030398764392024713, 0.0, 7.020499859590003e-05, 0.0, 0.006154638210240569, 0.0], [0.13524872010391992, 0.0003820585313670054, 0.0, 0.010621227172002751, 0.1194569674740837, 0.0006622347877028094, 0.002597998013295637, 0.19551208578487558, 0.07139400422811441, 0.0, 0.0007641170627340108, 0.024247981457425943, 0.010901403428338554, 0.015409694098469219, 0.22047324316751993, 0.0005348819439138076, 0.0, 0.07822011665520491, 0.06754794834568656, 0.010417462621940349, 0.016657751967601435, 0.00015282341254680218, 2.5470568757800363e-05, 0.0, 0.018771809174498867, 0.0], [0.1817185133110715, 0.0010963535782135296, 7.53220015566547e-05, 0.0002678115610903278, 0.5254755747487174, 0.0005523613447488011, 0.0001339057805451639, 0.0002887343393005097, 0.13398110254672058, 0.00011298300233498205, 6.695289027258195e-05, 0.0006444215688736013, 0.0008536493509754199, 0.0007741427937767288, 0.08021374710219521, 0.00015901311439738214, 7.950655719869107e-05, 0.0131729811611305, 0.0021759689338589137, 0.02477675395649736, 0.011197870898089332, 4.184555642036372e-06, 0.0003515026739310553, 0.0, 0.021738766560378955, 8.787566848276382e-05], [0.015545123176057688, 0.006009276291289088, 0.04379718551454075, 0.05285341879859614, 0.03829009287576315, 0.02388475731551804, 0.028861453737036327, 0.0005642512949567219, 3.949759064697053e-05, 0.0008971595589811879, 0.0051290442711566025, 0.0731721079299877, 0.053948066310812184, 0.2548384548542539, 0.027179984878065295, 0.006895150824371142, 0.0019071693769537202, 0.04498775574689944, 0.15196980127069393, 0.13697200185074423, 0.0005529662690575875, 0.02848340536941532, 1.6927538848701657e-05, 0.0018676717863067495, 0.0, 0.0013372755690474309], [0.12999518536350504, 0.0, 0.0, 0.0, 0.38517091959557054, 0.0, 0.0, 0.0, 0.001203659123736158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2623976889744824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22123254694270583, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012429239478218066, 0.0009844942160964804, 0.0027688899827713514, 6.153088850603002e-05, 0.5135367954713266, 0.0004307162195422102, 0.0, 0.00036918533103618014, 0.27325867585527935, 0.0, 0.002399704651735171, 0.011321683485109525, 0.002030519320698991, 0.11850849126261383, 0.010398720157519074, 0.0, 0.0, 0.0013536795471326606, 0.04676347526458282, 0.0006153088850603003, 0.0011690868816145706, 0.00012306177701206005, 0.0010460251046025104, 0.0, 0.0004307162195422102, 0.0], [0.08241255176144995, 0.0003121293464011486, 0.001394177747258464, 0.0869280229727199, 0.1822523253636307, 0.013536009322263147, 0.0006450673158957072, 0.00040576815032149324, 0.08058139292922988, 0.0, 0.006169756747196038, 0.2626672493081133, 0.002746738248330108, 0.0008323449237363963, 0.14607653411573757, 0.0023929916557421395, 0.0, 0.00035374659258796844, 0.03404290738081861, 0.03835029236115446, 0.005472667873566806, 0.014066629211145099, 0.0012069001394177748, 0.0, 0.03697692323698941, 0.00017687329629398422], [0.21052156650424111, 0.027449918787222524, 0.002634903447031222, 1.804728388377549e-05, 0.33280996210070385, 0.0025446670276123443, 5.4141851651326476e-05, 0.00018047283883775492, 0.09662515791373398, 0.00018047283883775492, 0.0, 0.0004511820970943873, 0.028243999278108646, 0.004981050351922036, 0.13075257173795343, 0.02447211694639957, 0.0, 0.0015701136978884679, 0.027684533477711604, 5.4141851651326476e-05, 0.0239306984298863, 0.0, 0.00016242555495397942, 0.0, 0.08458761956325574, 9.023641941887746e-05], [0.0305556246734181, 0.0002674861280449874, 0.02524322575829207, 0.38663564656995697, 0.09803677623230238, 0.001996815048893976, 0.12298763343203364, 0.003918982806240513, 0.023165542810221703, 0.001393416108885516, 0.005716738411007987, 0.003048097738187066, 0.0001679564059817363, 0.007054169051232924, 0.08635447510512827, 0.0001555151907238299, 0.0006469431934111324, 0.00039811888825300456, 0.04903082933140909, 0.13727014854811018, 0.004080718604593297, 0.0008833262833113539, 0.0004478837492846301, 0.0, 0.010537709323446715, 6.220607628953196e-06], [0.008162632836477422, 0.0061032300632816484, 0.005503404012836277, 0.03729418468644093, 0.005033540273320737, 0.18254206280178747, 0.0036889302102390306, 0.0030141259034879883, 0.011171760189545032, 0.00035489707984684443, 0.010821861660118566, 0.029301502564256364, 0.05827310080076778, 0.12604344740025392, 0.02460286516910096, 0.01910945825710544, 1.4995651261134271e-05, 0.1709054374231473, 0.025272670925431624, 0.0559187835527697, 0.15255076027951894, 0.019299403173079807, 0.04024832798488438, 0.0008997390756680562, 0.0034989852942646634, 0.0003698927311079787], [0.11623694864692094, 0.00018644790112934157, 7.990624334114639e-05, 0.0, 0.18530257830811847, 0.00010654165778819518, 0.0, 0.07841466013211165, 0.04908906882591093, 0.0, 7.990624334114639e-05, 0.12864905177924568, 0.00015981248668229278, 5.327082889409759e-05, 0.1417004048582996, 0.027913914340507138, 0.0, 0.155018112081824, 0.011533134455572129, 0.056999786916684426, 0.04538674621777115, 0.0, 0.0016780311101640742, 0.0, 0.0014116769656935862, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07636237136754903, 0.0027182706620930684, 0.01040385735551097, 0.11019513300110025, 0.3182560999288072, 0.0024351174681250406, 0.005242379134036632, 0.0005096757491424503, 0.10755776325156947, 0.00034787392401786294, 0.012766164002329947, 0.007539965050805773, 0.0092550643971264, 0.03689890621966216, 0.10115041097663581, 0.0036081807002782992, 0.0, 0.010953983560934567, 0.06230988285547861, 0.052852566176946475, 0.025483787457122518, 0.014351821888550904, 0.001310594783509158, 0.00012135136884344056, 0.02711798589088085, 0.0002507928289431105], [0.12207102440379075, 0.001492692748290346, 0.01244489186656021, 0.0020915055368486827, 0.1982851390287083, 0.0006422050196132884, 0.001970007289894817, 0.1717551289617107, 0.04788766619224494, 8.678446210990383e-06, 0.004087548165376471, 0.008487520394348596, 0.006422050196132885, 0.004113583504009442, 0.09299822959697296, 0.032787169785121674, 0.0002169611552747596, 0.02125351477071545, 0.058900614433991735, 0.1643524143437359, 0.02982781962717395, 0.0, 0.013659874336098865, 0.0, 0.004243760197174298, 0.0], [0.027512118988748318, 0.0005004516788457379, 0.0020357356427623237, 0.0, 0.06391785806681453, 0.0005046927947681594, 3.817004330179357e-05, 0.6592941934881906, 0.03659658929457519, 0.0, 0.0, 0.0051868847731215036, 0.0003350481578712991, 0.001497113920614792, 0.11855615449537082, 0.00015268017320717428, 0.0, 0.022969883835834884, 0.01921649624449185, 0.01083181006586453, 0.009665503187198615, 0.0, 0.007625526428513871, 0.0, 0.013563088719903981, 0.0], [0.012041583235044024, 0.017129769317277888, 0.018487533258359164, 0.03239432756397948, 0.0178017938941767, 0.003510985544614203, 0.04567024165455194, 0.0002742957456729846, 0.022670543379872177, 2.742957456729846e-05, 0.0021943659653838768, 0.0676139013083907, 0.016965191869874097, 0.2111391502317799, 0.0004251584057931261, 0.07710453410867597, 0.0, 0.1425789286008174, 0.15582741311682255, 0.15364676193872234, 0.0, 1.371478728364923e-05, 0.0, 2.742957456729846e-05, 0.0008503168115862522, 0.00160463011218696], [0.06396588486140725, 0.0, 0.0, 0.0, 0.7486377635631367, 0.0, 0.0, 0.0, 0.1442447625816496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04010559447659661, 0.0, 0.0, 0.0, 3.38443835245541e-05, 0.0, 0.0001353775340982164, 0.0, 0.0, 0.0, 0.0028767725995870984, 0.0], [0.17299145892646345, 0.0013367127282827582, 1.735990556211374e-05, 0.0005034372613012985, 0.18156725227414763, 0.0010589542392889382, 0.00012151933893479619, 0.22845635719741686, 0.24598986181515173, 0.0, 8.679952781056871e-05, 0.0069786820359697245, 8.679952781056871e-05, 0.03860842997014096, 0.09633011596416916, 3.471981112422748e-05, 0.0, 0.01545031595028123, 0.010172904659398654, 3.471981112422748e-05, 0.0, 0.0, 1.735990556211374e-05, 0.0, 0.00015623915005902368, 0.0], [0.15627906976744185, 0.0, 0.25116279069767444, 0.0, 0.31069767441860463, 0.0, 0.0, 0.03162790697674418, 0.0074418604651162795, 0.0, 0.0, 0.0018604651162790699, 0.0, 0.0, 0.0009302325581395349, 0.06604651162790698, 0.0, 0.0, 0.0018604651162790699, 0.17209302325581396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009044593279523727, 0.0001717327837884252, 0.0019463048829354856, 0.000572442612628084, 0.4150781384166237, 0.002232526189249528, 0.000286221306314042, 0.000286221306314042, 0.09914706050718415, 0.0, 0.0, 0.016200125937374778, 0.0019463048829354856, 0.004178831072185013, 0.29177399965653444, 0.044192569694888086, 0.0, 0.01826091934283588, 0.09239223767817277, 0.0010303967027305513, 0.0, 0.0, 0.000572442612628084, 0.0006869311351537008, 0.0, 0.0], [0.2562674094707521, 0.00238758456028651, 0.0, 0.0, 0.30043772383605255, 0.0, 0.0015917230401910067, 0.004377238360525269, 0.2124950258654994, 0.0003979307600477517, 0.0015917230401910067, 0.00238758456028651, 0.00477516912057302, 0.0031834460803820135, 0.03979307600477517, 0.019896538002387585, 0.0, 0.045762037405491444, 0.0, 0.0003979307600477517, 0.017906884202148827, 0.0, 0.0, 0.0, 0.0, 0.08635097493036212]]
    # prior = [0.06823111913526092, 0.012159462518893252, 0.0135915884042477, 0.03913981045513515, 0.10230816689170402, 0.020709598093305904, 0.013664504100095792, 0.07014823709616835, 0.04800189170016552, 0.0021330408489646357, 0.00544865104678954, 0.03239074391725198, 0.0198510414492354, 0.05577588590644865, 0.06025789049243512, 0.010681379205521875, 0.00024005695640129206, 0.04224334894602159, 0.04716233421628079, 0.07883547471840806, 0.020805877621274334, 0.007586056567688745, 0.01627663188023135, 0.0003653487154642124, 0.01459648993083022, 0.000696036800859789]
    # print(p)
    # print(prior)

    # for row in p:
    #     print(row)
        
    # Run the Viterbi algorithm on each word of the messages to determine the
    # most likely sequence of characters.

    # print()
    # for row in msgs:
    #     print(row)
    # print()


    # decoding one message (line) at a time
    for msg in msgs:
        s_in = msg.split(' ') #divide each message into a list of words
        output='' # initialise output string
        
        # decoding message, one word at a time (word by word)
        for i in range(len(s_in)):
            y=[]
            # print("coded word: " + s_in[i])
            
            # convert letters to numbers, one letter at a time (letter by letter)
            for j in range(len(s_in[i])):
                y.append(ord(s_in[i][j])-97) #convert the letters to numbers 0-25
            # end

            # print("coded number array, y: " + str(y))

            x=HMM(p,prior,b,y) #perform the Viterbi algorithm
            # print(x)

            for j in range(len(x)):
                output=output+chr(x[j]+97) #convert the states x back to letters
                    
            if i!=len(s_in)-1:
                output=output+' ' #recreate the message
        # print("--")
                
        print(msg) #display received message
        print(output) #display decoded message
        print('')
        # print("--")

if __name__ == "__main__":
    # 1.
    # constructTransitions('bible.txt')
    main()

    # 2.
    # pr_correct= 0.5
    # adj=[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,1],[0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0],[0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0],[0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0],[0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0],[0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0],[0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0],[0,1,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,0],[0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,1,1,0,1,0,1,1,0,0,0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,0,1,1,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0],[0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],[1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1],[0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0],[0,1,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0],[0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1],[0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0]]
    # constructEmissions(pr_correct, adj)

    # 3.
    # HMM(p,pi,b,y)
